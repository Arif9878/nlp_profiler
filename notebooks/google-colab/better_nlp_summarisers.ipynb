{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "better_nlp_summarisers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp/notebooks/google-colab/better_nlp_summarisers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iFyUOrS1fczL"
      },
      "source": [
        "# Better NLP\n",
        "\n",
        "This is a wrapper program/library that encapsulates a couple of NLP libraries that are popular among the AI and ML communities.\n",
        "\n",
        "Examples have been used to illustrate the usage as much as possible. Not all the APIs of the underlying libraries have been covered.\n",
        "\n",
        "The idea is to keep the API language as high-level as possible, so its easier to use and stays human-readable.\n",
        "\n",
        "Libraries / frameworks covered:\n",
        "\n",
        "- nltk [site](http://www.nltk.org/) | [docs](https://buildmedia.readthedocs.org/media/pdf/nltk/latest/nltk.pdf)\n",
        "- numpy [site](https://www.numpy.org/) | [docs](https://docs.scipy.org/doc/)\n",
        "- networkx [site](https://networkx.github.io/) | [docs](https://networkx.github.io/documentation/stable/index.html)\n",
        "\n",
        "See [https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp](https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp) for more details.\n",
        "\n",
        "### This notebook will demonstrate the below NLP features / functionalities, using the above mentioned libraries\n",
        "\n",
        "- Cosine similarity summarisation technqiue (using TextRank)\n",
        "- Summarisation 2 (TODO)\n",
        "- Summarisation 3 (TODO)\n",
        "- Summarisation 4 (TODO)\n",
        "- Summarisation 5 (TODO)\n",
        "\n",
        "_Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNN4hI_22qx2",
        "colab_type": "text"
      },
      "source": [
        "### Resources\n",
        "\n",
        "- [Understand Text Summarization and create your own summarizer in python](https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70)\n",
        "- [Beyond bag of words: Using PyTextRank to find Phrases and Summarize text](https://medium.com/@aneesha/beyond-bag-of-words-using-pytextrank-to-find-phrases-and-summarize-text-f736fa3773c5)\n",
        "- [Build a simple text summarisation tool using NLTK](https://medium.com/@wilamelima/build-a-simple-text-summarisation-tool-using-nltk-ff0984fedb4f)\n",
        "- [Summarise Text with TFIDF in Python](https://medium.com/@shivangisareen/summarise-text-with-tfidf-in-python-bc7ca10d3284)\n",
        "- [How to Make a Text Summarizer - Intro to Deep Learning #10 by Siraj Raval](https://www.youtube.com/watch?v=ogrJaOIuBx4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lre8GErufczN"
      },
      "source": [
        "#### Setup and installation ( optional )\n",
        "\n",
        "In case, this notebook is running in a local environment (Linux/MacOS) or _Google Colab_ environment and in case it does not have the necessary dependencies installed then please execute the steps in the next section.\n",
        "\n",
        "Otherwise, please SKIP to the **Install Spacy model ( NOT optional )** section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJuCUOMOfczO",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "%%bash\n",
        "\n",
        "apt-get install apt-utils dselect dpkg\n",
        "\n",
        "echo \"OSTYPE=$OSTYPE\"\n",
        "if [[ \"$OSTYPE\" == \"cygwin\" ]] || [[ \"$OSTYPE\" == \"msys\" ]] ; then\n",
        "    echo \"Windows or Windows-like environment detected, script not tested, and may not work.\"\n",
        "    echo \"Try installing the components mention in the install-[ostype].sh scripts manually.\"\n",
        "    echo \"Or try running under CGYWIN or git-bash.\"\n",
        "    echo \"If successfully installed, please contribute back with the solution via a pull request, to https://github.com/neomatrix369/awesome-ai-ml-dl/\"\n",
        "    echo \"Please give the file a good name, i.e. install-windows.sh or install-windows.bat depending on what kind of script you end up writing\"\n",
        "    exit 0\n",
        "elif [[ \"$OSTYPE\" == \"linux-gnu\" ]] || [[ \"$OSTYPE\" == \"linux\" ]]; then\n",
        "    TARGET_OS=\"linux\"\n",
        "else\n",
        "    TARGET_OS=\"macos\"\n",
        "fi\n",
        "\n",
        "if [[ -e ../../library/org/neomatrix369 ]]; then\n",
        "  echo \"Library source found\"\n",
        "  \n",
        "  cd ../../build\n",
        "  \n",
        "  echo \"Detected OS: ${TARGET_OS}\"\n",
        "  ./install-${TARGET_OS}.sh || true\n",
        "else\n",
        "  if [[ -e awesome-ai-ml-dl/examples/better-nlp/library ]]; then\n",
        "     echo \"Library source found\"\n",
        "  else\n",
        "     git clone \"https://github.com/neomatrix369/awesome-ai-ml-dl\"\n",
        "  fi\n",
        "\n",
        "  echo \"Library source exists\"\n",
        "  cd awesome-ai-ml-dl/examples/better-nlp/build\n",
        "\n",
        "  echo \"Detected OS: ${TARGET_OS}\"\n",
        "  ./install-${TARGET_OS}.sh || true \n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kwXgEdM8oeUv"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AX1pZlKofczb"
      },
      "source": [
        "### Cosine similarity summarisation technqiue\n",
        "\n",
        "**Abstractive Summarization:** Abstractive methods select words based on semantic understanding, even those words did not appear in the source documents. It aims at producing important material in a new way. They interpret and examine the text using advanced natural language techniques in order to generate a new shorter text that conveys the most critical information from the original text.\n",
        "\n",
        "**Flow:** Input document → understand context → semantics → create own summary\n",
        "\n",
        "**Extractive Summarization:** Extractive methods attempt to summarize articles by selecting a subset of words that retain the most important points.\n",
        "\n",
        "**Flow:** Input document → sentences similarity → weight sentences → select sentences with higher rank\n",
        "\n",
        "**Cosine similarity** is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. Its measures cosine of the angle between vectors. Angle will be 0 if sentences are similar and tend towards 90 as they begin to differ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvIayfUI2qx-",
        "colab_type": "code",
        "colab": {},
        "outputId": "72bdb042-1e7d-4491-b611-2ff00c782708"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../../library')\n",
        "sys.path.insert(0, './awesome-ai-ml-dl/examples/better-nlp/library')\n",
        "\n",
        "from org.neomatrix369.better_nlp import BetterNLP"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flMJvX-a2qyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "betterNLP = BetterNLP() ### do not re-run this unless you wish to re-initialise the object"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa4tGzNW2qyJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "f3894c97-f379-42a1-b123-2331e371dca6"
      },
      "source": [
        "generic_text=\"\"\"We all interact with applications which uses text summarization. Many of those applications are for the platform which publishes articles on daily news, entertainment, sports. With our busy schedule, we prefer to read the summary of those article before we decide to jump in for reading entire article. Reading a summary help us to identify the interest area, gives a brief context of the story.\n",
        "Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning.\n",
        "Summarization systems often have additional evidence they can utilize in order to specify the most important topics of document(s). For example, when summarizing blogs, there are discussions or comments coming after the blog post that are good sources of information to determine which parts of the blog are critical and interesting.\n",
        "In scientific paper summarization, there is a considerable amount of information such as cited papers and conference information which can be leveraged to identify important sentences in the original paper.\n",
        "In general there are two types of summarization, abstractive and extractive summarization.\n",
        "1. Abstractive Summarization: Abstractive methods select words based on semantic understanding, even those words did not appear in the source documents. It aims at producing important material in a new way. They interpret and examine the text using advanced natural language techniques in order to generate a new shorter text that conveys the most critical information from the original text.\n",
        "It can be correlated to the way human reads a text article or blog post and then summarizes in their own word.\n",
        "Input document → understand context → semantics → create own summary.\n",
        "2. Extractive Summarization: Extractive methods attempt to summarize articles by selecting a subset of words that retain the most important points.\n",
        "This approach weights the important part of sentences and uses the same to form the summary. Different algorithm and techniques are used to define weights for the sentences and further rank them based on importance and similarity among each other.\n",
        "Input document → sentences similarity → weight sentences → select sentences with higher rank.\n",
        "The limited study is available for abstractive summarization as it requires a deeper understanding of the text as compared to the extractive approach.\n",
        "Purely extractive summaries often times give better results compared to automatic abstractive summaries. This is because of the fact that abstractive summarization methods cope with problems such as semantic representation,\n",
        "inference and natural language generation which is relatively harder than data-driven approaches such as sentence extraction.\n",
        "There are many techniques available to generate extractive summarization. To keep it simple, I will be using an unsupervised learning approach to find the sentences similarity and rank them. One benefit of this will be, you don’t need to train and build a model prior start using it for your project.\n",
        "It’s good to understand Cosine similarity to make the best use of code you are going to see. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. Since we will be representing our sentences as the bunch of vectors, we can use it to find the similarity among sentences. Its measures cosine of the angle between vectors. Angle will be 0 if sentences are similar.\n",
        "All good till now..? Hope so :)\n",
        "Next, Below is our code flow to generate summarize text:-\n",
        "Input article → split into sentences → remove stop words → build a similarity matrix → generate rank based on matrix → pick top N sentences for summary.\n",
        "Let’s create these methods.\n",
        "\"\"\"\n",
        "\n",
        "summarised_result = betterNLP.summarise(generic_text)\n",
        "\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"summarisation_processing_time_in_secs=\",summarised_result['summarisation_processing_time_in_secs'])\n",
        "print(\"summarised_text=\",summarised_result['summarised_text'])\n",
        "print(\"ranked_sentences=\",summarised_result['ranked_sentences'])\n",
        "\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "summarisation_processing_time_in_secs= 0.16927456855773926\n",
            "summarised_text= Different algorithm and techniques are used to define weights for the sentences and further rank them based on importance and similarity among each other.\n",
            "Input document → sentences similarity → weight sentences → select sentences with higher rank.\n",
            "The limited study is available for abstractive summarization as it requires a deeper understanding of the text as compared to the extractive approach.\n",
            "Purely extractive summaries often times give better results compared to automatic abstractive summaries. Extractive Summarization: Extractive methods attempt to summarize articles by selecting a subset of words that retain the most important points.\n",
            "This approach weights the important part of sentences and uses the same to form the summary. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. They interpret and examine the text using advanced natural language techniques in order to generate a new shorter text that conveys the most critical information from the original text.\n",
            "It can be correlated to the way human reads a text article or blog post and then summarizes in their own word.\n",
            "Input document → understand context → semantics → create own summary.\n",
            "2. Since we will be representing our sentences as the bunch of vectors, we can use it to find the similarity among sentences\n",
            "ranked_sentences= [(0.11607479058765294, ['Different', 'algorithm', 'and', 'techniques', 'are', 'used', 'to', 'define', 'weights', 'for', 'the', 'sentences', 'and', 'further', 'rank', 'them', 'based', 'on', 'importance', 'and', 'similarity', 'among', 'each', 'other.\\nInput', 'document', '→', 'sentences', 'similarity', '→', 'weight', 'sentences', '→', 'select', 'sentences', 'with', 'higher', 'rank.\\nThe', 'limited', 'study', 'is', 'available', 'for', 'abstractive', 'summarization', 'as', 'it', 'requires', 'a', 'deeper', 'understanding', 'of', 'the', 'text', 'as', 'compared', 'to', 'the', 'extractive', 'approach.\\nPurely', 'extractive', 'summaries', 'often', 'times', 'give', 'better', 'results', 'compared', 'to', 'automatic', 'abstractive', 'summaries']), (0.0989155264644659, ['Extractive', 'Summarization:', 'Extractive', 'methods', 'attempt', 'to', 'summarize', 'articles', 'by', 'selecting', 'a', 'subset', 'of', 'words', 'that', 'retain', 'the', 'most', 'important', 'points.\\nThis', 'approach', 'weights', 'the', 'important', 'part', 'of', 'sentences', 'and', 'uses', 'the', 'same', 'to', 'form', 'the', 'summary']), (0.08112208384509272, ['Cosine', 'similarity', 'is', 'a', 'measure', 'of', 'similarity', 'between', 'two', 'non-zero', 'vectors', 'of', 'an', 'inner', 'product', 'space', 'that', 'measures', 'the', 'cosine', 'of', 'the', 'angle', 'between', 'them']), (0.07751914212038269, ['They', 'interpret', 'and', 'examine', 'the', 'text', 'using', 'advanced', 'natural', 'language', 'techniques', 'in', 'order', 'to', 'generate', 'a', 'new', 'shorter', 'text', 'that', 'conveys', 'the', 'most', 'critical', 'information', 'from', 'the', 'original', 'text.\\nIt', 'can', 'be', 'correlated', 'to', 'the', 'way', 'human', 'reads', 'a', 'text', 'article', 'or', 'blog', 'post', 'and', 'then', 'summarizes', 'in', 'their', 'own', 'word.\\nInput', 'document', '→', 'understand', 'context', '→', 'semantics', '→', 'create', 'own', 'summary.\\n2']), (0.07597104608017971, ['Since', 'we', 'will', 'be', 'representing', 'our', 'sentences', 'as', 'the', 'bunch', 'of', 'vectors,', 'we', 'can', 'use', 'it', 'to', 'find', 'the', 'similarity', 'among', 'sentences']), (0.07239804426425565, ['To', 'keep', 'it', 'simple,', 'I', 'will', 'be', 'using', 'an', 'unsupervised', 'learning', 'approach', 'to', 'find', 'the', 'sentences', 'similarity', 'and', 'rank', 'them']), (0.06619760533272526, ['This', 'is', 'because', 'of', 'the', 'fact', 'that', 'abstractive', 'summarization', 'methods', 'cope', 'with', 'problems', 'such', 'as', 'semantic', 'representation,\\ninference', 'and', 'natural', 'language', 'generation', 'which', 'is', 'relatively', 'harder', 'than', 'data-driven', 'approaches', 'such', 'as', 'sentence', 'extraction.\\nThere', 'are', 'many', 'techniques', 'available', 'to', 'generate', 'extractive', 'summarization']), (0.06615596111326189, ['For', 'example,', 'when', 'summarizing', 'blogs,', 'there', 'are', 'discussions', 'or', 'comments', 'coming', 'after', 'the', 'blog', 'post', 'that', 'are', 'good', 'sources', 'of', 'information', 'to', 'determine', 'which', 'parts', 'of', 'the', 'blog', 'are', 'critical', 'and', 'interesting.\\nIn', 'scientific', 'paper', 'summarization,', 'there', 'is', 'a', 'considerable', 'amount', 'of', 'information', 'such', 'as', 'cited', 'papers', 'and', 'conference', 'information', 'which', 'can', 'be', 'leveraged', 'to', 'identify', 'important', 'sentences', 'in', 'the', 'original', 'paper.\\nIn', 'general', 'there', 'are', 'two', 'types', 'of', 'summarization,', 'abstractive', 'and', 'extractive', 'summarization.\\n1']), (0.05537682344180091, ['We', 'all', 'interact', 'with', 'applications', 'which', 'uses', 'text', 'summarization']), (0.05237543897632098, ['Reading', 'a', 'summary', 'help', 'us', 'to', 'identify', 'the', 'interest', 'area,', 'gives', 'a', 'brief', 'context', 'of', 'the', 'story.\\nSummarization', 'can', 'be', 'defined', 'as', 'a', 'task', 'of', 'producing', 'a', 'concise', 'and', 'fluent', 'summary', 'while', 'preserving', 'key', 'information', 'and', 'overall', 'meaning.\\nSummarization', 'systems', 'often', 'have', 'additional', 'evidence', 'they', 'can', 'utilize', 'in', 'order', 'to', 'specify', 'the', 'most', 'important', 'topics', 'of', 'document(s)']), (0.04927996537372592, ['One', 'benefit', 'of', 'this', 'will', 'be,', 'you', 'don’t', 'need', 'to', 'train', 'and', 'build', 'a', 'model', 'prior', 'start', 'using', 'it', 'for', 'your', 'project.\\nIt’s', 'good', 'to', 'understand', 'Cosine', 'similarity', 'to', 'make', 'the', 'best', 'use', 'of', 'code', 'you', 'are', 'going', 'to', 'see']), (0.049028209139102934, ['Its', 'measures', 'cosine', 'of', 'the', 'angle', 'between', 'vectors']), (0.04515024869957921, ['Abstractive', 'Summarization:', 'Abstractive', 'methods', 'select', 'words', 'based', 'on', 'semantic', 'understanding,', 'even', 'those', 'words', 'did', 'not', 'appear', 'in', 'the', 'source', 'documents']), (0.03956945929957225, ['It', 'aims', 'at', 'producing', 'important', 'material', 'in', 'a', 'new', 'way']), (0.027534385680139446, ['With', 'our', 'busy', 'schedule,', 'we', 'prefer', 'to', 'read', 'the', 'summary', 'of', 'those', 'article', 'before', 'we', 'decide', 'to', 'jump', 'in', 'for', 'reading', 'entire', 'article']), (0.027331269581741646, ['Many', 'of', 'those', 'applications', 'are', 'for', 'the', 'platform', 'which', 'publishes', 'articles', 'on', 'daily', 'news,', 'entertainment,', 'sports'])]\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T7A3p05vfcz0"
      },
      "source": [
        "### Summarisation 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzuMRos32qyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s2kyTI6bfcz7"
      },
      "source": [
        "### Summarisation 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNJtjYX-2qyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4jQLb4Sqfc0E"
      },
      "source": [
        "### Summarisation 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8yJiTda2qyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H_JfZhqwfc0J",
        "colab": {}
      },
      "source": [
        "### Summarisation 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhimz66o2qyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}