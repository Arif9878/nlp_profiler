{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "better-nlp-spacy-texacy-examples.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp/notebooks/google-colab/better_nlp_spacy_texacy_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFyUOrS1fczL",
        "colab_type": "text"
      },
      "source": [
        "# Better NLP\n",
        "\n",
        "This is a wrapper program/library that encapsulates a couple of NLP libraries that are popular among the AI and ML communities.\n",
        "\n",
        "Examples have been used to illustrate the usage as much as possible. Not all the APIs of the underlying libraries have been covered.\n",
        "\n",
        "The idea is to keep the API language as high-level as possible, so its easier to use and stays human-readable.\n",
        "\n",
        "Libraries / frameworks covered:\n",
        "\n",
        "- SpaCy ([site](https://spacy.io/) | [docs](https://spacy.io/usage/))\n",
        "- Textacy ([github](https://github.com/chartbeat-labs/textacy) | [docs](https://chartbeat-labs.github.io/textacy/))\n",
        "\n",
        "See [https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp](https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp) for more details.\n",
        "\n",
        "This notebook will demonstrate the below NLP features / functionalities, using the above mentioned libraries\n",
        "\n",
        "    Extract entities\n",
        "    Noun extraction\n",
        "    Gather facts\n",
        "    Obfuscate privacy details\n",
        "    Parts-of-speech\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lre8GErufczN",
        "colab_type": "text"
      },
      "source": [
        "#### Setup and installation ( optional )\n",
        "\n",
        "In case, this notebook is running in a local environment (Linux/MacOS) or _Google Colab_ environment and in case it does not have the necessary dependencies installed then please execute the steps in the next section.\n",
        "\n",
        "Otherwise, please SKIP to the **Examples** section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJuCUOMOfczO",
        "colab_type": "code",
        "outputId": "9b4bbb58-49c7-4155-8c98-479fde4694f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3595
        }
      },
      "source": [
        "%%time\n",
        "%%bash\n",
        "\n",
        "apt-get install apt-utils dselect dpkg\n",
        "\n",
        "echo \"OSTYPE=$OSTYPE\"\n",
        "if [[ \"$OSTYPE\" == \"cygwin\" ]] || [[ \"$OSTYPE\" == \"msys\" ]] ; then\n",
        "    echo \"Windows or Windows-like environment detected, script not tested, and may not work.\"\n",
        "    echo \"Try installing the components mention in the install-[ostype].sh scripts manually.\"\n",
        "    echo \"Or try running under CGYWIN or git-bash.\"\n",
        "    echo \"If successfully installed, please contribute back with the solution via a pull request, to https://github.com/neomatrix369/awesome-ai-ml-dl/\"\n",
        "    echo \"Please give the file a good name, i.e. install-windows.sh or install-windows.bat depending on what kind of script you end up writing\"\n",
        "    exit 0\n",
        "elif [[ \"$OSTYPE\" == \"linux-gnu\" ]] || [[ \"$OSTYPE\" == \"linux\" ]]; then\n",
        "    TARGET_OS=\"linux\"\n",
        "else\n",
        "    TARGET_OS=\"macos\"\n",
        "fi\n",
        "\n",
        "\n",
        "if [[ -e ../../library/org/neomatrix369 ]]; then\n",
        "  echo \"Library source found\"\n",
        "  \n",
        "  cd ../../build\n",
        "  \n",
        "  echo \"Detected OS: ${TARGET_OS}\"\n",
        "  ./install-${TARGET_OS}.sh || true\n",
        "else\n",
        "  if [[ -e awesome-ai-ml-dl/examples/better-nlp/library ]]; then\n",
        "     echo \"Library source found\"\n",
        "  else\n",
        "     git clone \"https://github.com/neomatrix369/awesome-ai-ml-dl\"\n",
        "  fi\n",
        "\n",
        "  echo \"Library source exists\"\n",
        "  cd awesome-ai-ml-dl/examples/better-nlp/build\n",
        "\n",
        "  echo \"Detected OS: ${TARGET_OS}\"\n",
        "  ./install-${TARGET_OS}.sh || true \n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "apt-utils is already the newest version (1.6.10).\n",
            "dpkg is already the newest version (1.19.0.5ubuntu2.1).\n",
            "dselect is already the newest version (1.19.0.5ubuntu2.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "OSTYPE=linux-gnu\n",
            "Library source found\n",
            "Library source exists\n",
            "Detected OS: linux\n",
            "Please check if you fulfill the requirements mentioned in the README file.\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://deb.nodesource.com/node_8.x bionic InRelease\n",
            "Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "liblapack-dev is already the newest version (3.7.1-4ubuntu1).\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu2).\n",
            "curl is already the newest version (7.58.0-2ubuntu3.6).\n",
            "wget is already the newest version (1.19.4-1ubuntu2.2).\n",
            "libswscale-dev is already the newest version (7:3.4.4-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "vim is already the newest version (2:8.0.1453-1ubuntu1).\n",
            "zip is already the newest version (3.0-11build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "\n",
            "## Installing the NodeSource Node.js 8.x LTS Carbon repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://deb.nodesource.com/node_8.x bionic InRelease\n",
            "Hit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:9 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists...\n",
            "\n",
            "## Confirming \"bionic\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_8.x/dists/bionic/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | apt-key add -\n",
            "OK\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 8.x LTS Carbon repo...\n",
            "\n",
            "+ echo 'deb https://deb.nodesource.com/node_8.x bionic main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src https://deb.nodesource.com/node_8.x bionic main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Hit:6 https://deb.nodesource.com/node_8.x bionic InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Reading package lists...\n",
            "\n",
            "## Run `sudo apt-get install -y nodejs` to install Node.js 8.x LTS Carbon and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -\n",
            "     echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "nodejs is already the newest version (8.15.1-1nodesource1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Install components using python and pip\n",
            "/usr/bin/npm -> /usr/lib/node_modules/npm/bin/npm-cli.js\n",
            "/usr/bin/npx -> /usr/lib/node_modules/npm/bin/npx-cli.js\n",
            "+ npm@6.9.0\n",
            "updated 1 package in 6.171s\n",
            "6.9.0\n",
            "Python 3.6.7\n",
            "pip 19.0.3 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already satisfied: textacy in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.2)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.2)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (3.1.0)\n",
            "Requirement already satisfied: srsly>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.0.5)\n",
            "Requirement already satisfied: ijson>=2.3 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.20.3)\n",
            "Requirement already satisfied: pyphen>=0.9.4 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.9.5)\n",
            "Requirement already satisfied: cytoolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.9.0.1)\n",
            "Requirement already satisfied: pyemd>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.11.1 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.28.1)\n",
            "Requirement already satisfied: mwparserfromhell>=0.4.4 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.5.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.2.1)\n",
            "Requirement already satisfied: ftfy<5.0.0,>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.4.3)\n",
            "Requirement already satisfied: python-levenshtein>=0.12.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.12.0)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.11->textacy) (4.4.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz>=0.8.0->textacy) (0.9.0)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.2.0->textacy) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.2.0->textacy) (0.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein>=0.12.0->textacy) (40.9.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy<5.0.0,>=4.2.0->textacy) (0.5.1)\n",
            "Requirement already satisfied: jupyterlab in /root/.local/lib/python3.6/site-packages (0.35.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.23.4)\n",
            "Requirement already satisfied: notebook>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from jupyterlab) (5.2.2)\n",
            "Requirement already satisfied: jupyterlab-server<0.3.0,>=0.2.0 in /root/.local/lib/python3.6/site-packages (from jupyterlab) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (0.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (5.4.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.3.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (5.2.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (2.10.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.5.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.6.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (0.8.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.4.0)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyterlab-server<0.3.0,>=0.2.0->jupyterlab) (2.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (3.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (2.1.3)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.8.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab) (4.4.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook>=4.3.1->jupyterlab) (17.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.3.1->jupyterlab) (1.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook>=4.3.1->jupyterlab) (5.5.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook>=4.3.1->jupyterlab) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (1.0.15)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (4.7.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (40.9.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.1.7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25.6 ms, sys: 8.9 ms, total: 34.5 ms\n",
            "Wall time: 31.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtvtZg2afczS",
        "colab_type": "text"
      },
      "source": [
        "#### Install Spacy model ( NOT optional )\n",
        "\n",
        "Install the large English language model for spaCy - will be needed for the examples in this notebooks.\n",
        "\n",
        "**Note:** from observation it appears that spaCy model should be installed towards the end of the installation process, it avoid errors when running programs using the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLvwAn-DfczT",
        "colab_type": "code",
        "outputId": "57d1cd1a-e6a3-4d4c-a229-7fb4b283e3bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "%%time\n",
        "%%bash\n",
        "\n",
        "python -m spacy download en_core_web_lg\n",
        "python -m spacy link en_core_web_lg en || true"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz#egg=en_core_web_lg==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_lg -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_lg\n",
            "\n",
            "    You can now load the model via spacy.load('en_core_web_lg')\n",
            "\n",
            "\n",
            "\u001b[93m    Link 'en' already exists\u001b[0m\n",
            "    To overwrite an existing link, use the --force flag.\n",
            "\n",
            "CPU times: user 6.55 ms, sys: 5.76 ms, total: 12.3 ms\n",
            "Wall time: 2.82 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwXgEdM8oeUv",
        "colab_type": "text"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX1pZlKofczb",
        "colab_type": "text"
      },
      "source": [
        "### Extract entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe2IZleafczd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.insert(0, '../../library')\n",
        "sys.path.insert(0, './awesome-ai-ml-dl/examples/better-nlp/library')\n",
        "\n",
        "from org.neomatrix369.better_nlp import BetterNLP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu1TA5ZJfczi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can be any factual text or any text to experiment with\n",
        "generic_text = \"\"\"Denis Guedj (1940 – April 24, 2010) was a French novelist and \n",
        "a professor of the History of Science at Paris VIII University. He was born \n",
        "in Setif. He spent many years devising courses and games to teach adults \n",
        "and children math. He is the author of Numbers: The Universal Language and \n",
        "of the novel The Parrot's Theorem. He died in Paris. \n",
        "\"\"\"\n",
        "\n",
        "betterNLP = BetterNLP() ### do not re-run this unless you wish to re-initialise the object"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaihh-wofczq",
        "colab_type": "code",
        "outputId": "8c4f0ace-b092-4510-f1d2-e9b967c83f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model_loading_result = betterNLP.load_nlp_model()\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"model_loading_time_in_secs=\",model_loading_result['model_loading_time_in_secs'])\n",
        "print(\"model_loading_method=\",model_loading_result['model_loading_method'])\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "\n",
        "model = model_loading_result[\"model\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model 'en'...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "model_loading_time_in_secs= 1.0047590732574463\n",
            "model_loading_method= directly, first time\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "empjCbipfczu",
        "colab_type": "code",
        "outputId": "e695056c-b118-4d36-82ce-3c6d8b13a339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "extracted_entities = betterNLP.extract_entities(model, generic_text)\n",
        "\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"extract_entities_processing_time_in_secs=\", extracted_entities['extract_entities_processing_time_in_secs'])\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "betterNLP.pretty_print(extracted_entities[\"extracted_entities\"])\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "betterNLP.pretty_print(betterNLP.token_entity_types())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "extract_entities_processing_time_in_secs= 0.052892446517944336\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Denis Guedj (PERSON)\n",
            "1940 – April 24, 2010 (DATE)\n",
            "French (NORP)\n",
            "the History of Science at Paris VIII University (ORG)\n",
            "Setif (PERSON)\n",
            "many years (DATE)\n",
            "Theorem (GPE)\n",
            "Paris (GPE)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "                                   Token entity types\n",
            "0                PERSON = People, including fictional\n",
            "1   NORP = Nationalities or religious or political...\n",
            "2   FAC = Buildings, airports, highways, bridges, etc\n",
            "3        ORG = Companies, agencies, institutions, etc\n",
            "4                     GPE = Countries, cities, states\n",
            "5   LOC = Non-GPE locations, mountain ranges, bodi...\n",
            "6   PRODUCT = Objects, vehicles, foods, etc. (Not ...\n",
            "7   EVENT = Named hurricanes, battles, wars, sport...\n",
            "8           WORK_OF_ART = Titles of books, songs, etc\n",
            "9                LAW = Named documents made into laws\n",
            "10                      LANGUAGE = Any named language\n",
            "11       DATE = Absolute or relative dates or periods\n",
            "12                    TIME = Times smaller than a day\n",
            "13                PERCENT = Percentage, including ”%“\n",
            "14            MONEY = Monetary values, including unit\n",
            "15  QUANTITY = Measurements, as of weight or distance\n",
            "16                   ORDINAL = “first”, “second”, etc\n",
            "17  CARDINAL = Numerals that do not fall under ano...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7A3p05vfcz0",
        "colab_type": "text"
      },
      "source": [
        "### Noun extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hetkfphHfcz2",
        "colab_type": "code",
        "outputId": "3dbd5c48-4a1e-49ed-a7ce-28a093967921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "chunks = betterNLP.extract_noun_chunks(model, generic_text)\n",
        "chunks = chunks.get(\"noun_chunks\")\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "betterNLP.pretty_print(chunks)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "A list of words that belong together (in lowercase):\n",
            "french novelist\n",
            "children math\n",
            "parrot's theorem\n",
            "universal language\n",
            "many years\n",
            "paris viii university\n",
            "denis guedj\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2kyTI6bfcz7",
        "colab_type": "text"
      },
      "source": [
        "### Gather facts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw8PDy9Ofcz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_topic = \"Denis Guedj\"\n",
        "extracted_facts = betterNLP.extract_facts(model, generic_text, target_topic)\n",
        "\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Trying to gather details about \" + target_topic)\n",
        "betterNLP.pretty_print(extracted_facts.get(\"facts\"))\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jQLb4Sqfc0E",
        "colab_type": "text"
      },
      "source": [
        "### Obfuscate privacy details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bmI2UcSfc0F",
        "colab_type": "code",
        "outputId": "bc1dd0a0-d970-4b3b-ba6d-c0231c9f1900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "obfuscated_text = betterNLP.obfuscate_text(model, generic_text)\n",
        "obfuscated_text = obfuscated_text.get(\"obfuscated_text\")\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Obfuscated generic text: \", \"\".join(obfuscated_text))\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Obfuscated generic text:  [OBFUSCATED] (1940 – April 24, 2010) was a French novelist and a professor of the History of Science at Paris VIII University. He was born in [OBFUSCATED] . He spent many years devising courses and games to teach adults and children math. He is the author of Numbers: The Universal Language and of the novel The Parrot's Theorem. He died in Paris. \n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsYXQAE72YbP",
        "colab_type": "text"
      },
      "source": [
        "### Parts-of-speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUBxifxR2Xur",
        "colab_type": "code",
        "outputId": "43dac863-876d-469a-bd19-6bbe04536fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "generic_text = u'Apple is looking at buying U.K. startup for $1 billion'\n",
        "parts_of_speech_tagging = betterNLP.parts_of_speech_tagging(model, generic_text).get(\"parts_of_speech\")\n",
        "betterNLP.pretty_print(parts_of_speech_tagging)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      token    lemma parts-of-speech  tag       dep  shape  is_alphanumeric  \\\n",
            "0     Apple    apple           PROPN  NNP     nsubj  Xxxxx             True   \n",
            "1        is       be            VERB  VBZ       aux     xx             True   \n",
            "2   looking     look            VERB  VBG      ROOT   xxxx             True   \n",
            "3        at       at             ADP   IN      prep     xx             True   \n",
            "4    buying      buy            VERB  VBG     pcomp   xxxx             True   \n",
            "5      U.K.     u.k.           PROPN  NNP  compound   X.X.            False   \n",
            "6   startup  startup            NOUN   NN      dobj   xxxx             True   \n",
            "7       for      for             ADP   IN      prep    xxx             True   \n",
            "8         $        $             SYM    $  quantmod      $            False   \n",
            "9         1        1             NUM   CD  compound      d            False   \n",
            "10  billion  billion             NUM   CD      pobj   xxxx             True   \n",
            "\n",
            "    is_stop_word  \n",
            "0          False  \n",
            "1           True  \n",
            "2          False  \n",
            "3           True  \n",
            "4          False  \n",
            "5          False  \n",
            "6          False  \n",
            "7           True  \n",
            "8          False  \n",
            "9          False  \n",
            "10         False  \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}