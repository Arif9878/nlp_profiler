{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "better-nlp-spacy-texacy-examples.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp/notebooks/google-colab/better_nlp_spacy_texacy_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "iFyUOrS1fczL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Better NLP\n",
        "\n",
        "This is a wrapper program/library that encapsulates a couple of NLP libraries that are popular among the AI and ML communities.\n",
        "\n",
        "Examples have been used to illustrate the usage as much as possible. Not all the APIs of the underlying libraries have been covered.\n",
        "\n",
        "The idea is to keep the API language as high-level as possible, so its easier to use and stays human-readable.\n",
        "\n",
        "Libraries / frameworks covered:\n",
        "\n",
        "- SpaCy ([site](https://spacy.io/) | [docs](https://spacy.io/usage/))\n",
        "- Textacy ([github](https://github.com/chartbeat-labs/textacy) | [docs](https://chartbeat-labs.github.io/textacy/))\n",
        "\n",
        "See [https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp](https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp) for more details."
      ]
    },
    {
      "metadata": {
        "id": "Lre8GErufczN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Setup and installation ( optional )\n",
        "\n",
        "In case, this notebook is running in a local environment (Linux/MacOS) or _Google Colab_ environment and in case it does not have the necessary dependencies installed then please execute the steps in the next section.\n",
        "\n",
        "Otherwise, please SKIP to the **Examples** section."
      ]
    },
    {
      "metadata": {
        "id": "QJuCUOMOfczO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3613
        },
        "outputId": "978754d9-a406-446c-a9c6-9c358fd732a6"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%bash\n",
        "\n",
        "apt-get install apt-utils dselect dpkg\n",
        "\n",
        "echo \"OSTYPE=$OSTYPE\"\n",
        "if [[ \"$OSTYPE\" == \"cygwin\" ]] || [[ \"$OSTYPE\" == \"msys\" ]] ; then\n",
        "    echo \"Windows or Windows-like environment detected, script not tested, and may not work.\"\n",
        "    echo \"Try installing the components mention in the install-[ostype].sh scripts manually.\"\n",
        "    echo \"Or try running under CGYWIN or git-bash.\"\n",
        "    echo \"If successfully installed, please contribute back with the solution via a pull request, to https://github.com/neomatrix369/awesome-ai-ml-dl/\"\n",
        "    echo \"Please give the file a good name, i.e. install-windows.sh or install-windows.bat depending on what kind of script you end up writing\"\n",
        "    exit 0\n",
        "elif [[ \"$OSTYPE\" == \"linux-gnu\" ]] || [[ \"$OSTYPE\" == \"linux\" ]]; then\n",
        "    TARGET_OS=\"linux\"\n",
        "else\n",
        "    TARGET_OS=\"macos\"\n",
        "fi\n",
        "\n",
        "BASE_URL=\"https://raw.githubusercontent.com/neomatrix369/awesome-ai-ml-dl/master/examples/better-nlp\"\n",
        "if [[ ! -f \"install-${TARGET_OS}.sh\" ]]; then\n",
        "    wget ${BASE_URL}/install-${TARGET_OS}.sh\n",
        "    chmod +x ./install-${TARGET_OS}.sh\n",
        "fi\n",
        "\n",
        "\n",
        "if [[ ! -f \"install-dependencies.sh\" ]]; then\n",
        "    wget ${BASE_URL}/install-dependencies.sh\n",
        "    chmod +x ./install-dependencies.sh\n",
        "fi\n",
        "\n",
        "echo \"Detected OS: ${TARGET_OS}\"\n",
        "./install-${TARGET_OS}.sh || true"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "apt-utils is already the newest version (1.6.10).\n",
            "dpkg is already the newest version (1.19.0.5ubuntu2.1).\n",
            "dselect is already the newest version (1.19.0.5ubuntu2.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "OSTYPE=linux-gnu\n",
            "Detected OS: linux\n",
            "Please check if you fulfill the requirements mentioned in the README file.\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://deb.nodesource.com/node_8.x bionic InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Fetched 252 kB in 2s (133 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "liblapack-dev is already the newest version (3.7.1-4ubuntu1).\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu2).\n",
            "curl is already the newest version (7.58.0-2ubuntu3.6).\n",
            "wget is already the newest version (1.19.4-1ubuntu2.2).\n",
            "libswscale-dev is already the newest version (7:3.4.4-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "vim is already the newest version (2:8.0.1453-1ubuntu1).\n",
            "zip is already the newest version (3.0-11build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "\n",
            "## Installing the NodeSource Node.js 8.x LTS Carbon repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://deb.nodesource.com/node_8.x bionic InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (132 kB/s)\n",
            "Reading package lists...\n",
            "\n",
            "## Confirming \"bionic\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_8.x/dists/bionic/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | apt-key add -\n",
            "OK\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 8.x LTS Carbon repo...\n",
            "\n",
            "+ echo 'deb https://deb.nodesource.com/node_8.x bionic main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src https://deb.nodesource.com/node_8.x bionic main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://deb.nodesource.com/node_8.x bionic InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (130 kB/s)\n",
            "Reading package lists...\n",
            "\n",
            "## Run `sudo apt-get install -y nodejs` to install Node.js 8.x LTS Carbon and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -\n",
            "     echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "nodejs is already the newest version (8.15.1-1nodesource1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Install components using python and pip\n",
            "/usr/bin/npm -> /usr/lib/node_modules/npm/bin/npm-cli.js\n",
            "/usr/bin/npx -> /usr/lib/node_modules/npm/bin/npx-cli.js\n",
            "+ npm@6.9.0\n",
            "updated 1 package in 6.149s\n",
            "6.9.0\n",
            "Python 3.6.7\n",
            "pip 19.0.3 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already satisfied: textacy in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.2)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied: tqdm>=4.11.1 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.28.1)\n",
            "Requirement already satisfied: srsly>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.0.5)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (3.1.0)\n",
            "Requirement already satisfied: pyemd>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.5.1)\n",
            "Requirement already satisfied: ijson>=2.3 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.20.3)\n",
            "Requirement already satisfied: pyphen>=0.9.4 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.9.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.2.1)\n",
            "Requirement already satisfied: cytoolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.9.0.1)\n",
            "Requirement already satisfied: python-levenshtein>=0.12.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.12.0)\n",
            "Requirement already satisfied: mwparserfromhell>=0.4.4 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.5.3)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.2)\n",
            "Requirement already satisfied: ftfy<5.0.0,>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.4.3)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz>=0.8.0->textacy) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein>=0.12.0->textacy) (40.9.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.11->textacy) (4.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.2.0->textacy) (0.1.7)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from ftfy<5.0.0,>=4.2.0->textacy) (1.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy<5.0.0,>=4.2.0->textacy) (0.5.1)\n",
            "Requirement already satisfied: jupyterlab in /root/.local/lib/python3.6/site-packages (0.35.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.23.4)\n",
            "Requirement already satisfied: jupyterlab-server<0.3.0,>=0.2.0 in /root/.local/lib/python3.6/site-packages (from jupyterlab) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from jupyterlab) (5.2.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyterlab-server<0.3.0,>=0.2.0->jupyterlab) (2.6.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (0.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (2.10.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.4.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (5.2.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (5.4.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.3.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab) (4.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook>=4.3.1->jupyterlab) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.3.1->jupyterlab) (1.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook>=4.3.1->jupyterlab) (17.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook>=4.3.1->jupyterlab) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (2.1.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (3.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.3)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab) (4.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (1.0.15)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (40.9.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (4.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.1.7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22.3 ms, sys: 3.89 ms, total: 26.2 ms\n",
            "Wall time: 27.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RtvtZg2afczS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Install Spacy model ( NOT optional )\n",
        "\n",
        "Install the large English language model for spaCy - will be needed for the examples in this notebooks.\n",
        "\n",
        "**Note:** from observation it appears that spaCy model should be installed towards the end of the installation process, it avoid errors when running programs using the model."
      ]
    },
    {
      "metadata": {
        "id": "HLvwAn-DfczT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "27c42c18-e35a-4240-9367-3463c0473b7e"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%bash\n",
        "\n",
        "python -m spacy download en_core_web_lg\n",
        "python -m spacy link en_core_web_lg en || true"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz#egg=en_core_web_lg==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_lg -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_lg\n",
            "\n",
            "    You can now load the model via spacy.load('en_core_web_lg')\n",
            "\n",
            "\n",
            "\u001b[93m    Link 'en' already exists\u001b[0m\n",
            "    To overwrite an existing link, use the --force flag.\n",
            "\n",
            "CPU times: user 2.92 ms, sys: 7.01 ms, total: 9.93 ms\n",
            "Wall time: 2.46 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-foC9mxEmLjC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Clone the repo with the library code\n",
        "\n",
        "Eventually we won't do this, when the library can be installed "
      ]
    },
    {
      "metadata": {
        "id": "WcI9FxFfitpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06b13056-cab3-4b1c-d7ad-5354d4e34ced"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "if [[ -e awesome-ai-ml-dl/examples/better-nlp/ ]] || [[ -e org/neomatrix369 ]]; then\n",
        "   echo \"Library source exists\"\n",
        "else\n",
        "    git clone \"https://github.com/neomatrix369/awesome-ai-ml-dl\"\n",
        "fi"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Library source exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kwXgEdM8oeUv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Examples"
      ]
    },
    {
      "metadata": {
        "id": "AX1pZlKofczb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Extract entities"
      ]
    },
    {
      "metadata": {
        "id": "Pe2IZleafczd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'awesome-ai-ml-dl/examples/better-nlp/library')\n",
        "\n",
        "from org.neomatrix369.better_nlp import BetterNLP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cu1TA5ZJfczi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Can be any factual text or any text to experiment with\n",
        "generic_text = \"\"\"Denis Guedj (1940 – April 24, 2010) was a French novelist and \n",
        "a professor of the History of Science at Paris VIII University. He was born \n",
        "in Setif. He spent many years devising courses and games to teach adults \n",
        "and children math. He is the author of Numbers: The Universal Language and \n",
        "of the novel The Parrot's Theorem. He died in Paris. \n",
        "\"\"\"\n",
        "\n",
        "betterNLP = BetterNLP() ### do not re-run this unless you wish to re-initialise the object"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iaihh-wofczq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9f7e1766-6b12-4aad-c29c-c6f7431b1fe5"
      },
      "cell_type": "code",
      "source": [
        "model_loading_result = betterNLP.load_nlp_model()\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"model_loading_time_in_secs=\",model_loading_result['model_loading_time_in_secs'])\n",
        "print(\"model_loading_method=\",model_loading_result['model_loading_method'])\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "\n",
        "model = model_loading_result[\"model\"]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model 'en'...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "model_loading_time_in_secs= 0.6489133834838867\n",
            "model_loading_method= directly, first time\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "empjCbipfczu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "a7c2b175-c1d8-44a7-987d-49ea54610cca"
      },
      "cell_type": "code",
      "source": [
        "parsed_generic_text = betterNLP.extract_entities(model, generic_text)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"extract_entities_processing_time_in_secs=\", parsed_generic_text['extract_entities_processing_time_in_secs'])\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "\n",
        "parsed_generic_text = parsed_generic_text['parsed_text']\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "[print(f\"{each_entity.text} ({each_entity.label_})\") for each_entity in parsed_generic_text.ents if each_entity.text.strip() == each_entity.text]\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(betterNLP.token_entity_types())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "extract_entities_processing_time_in_secs= 0.04885745048522949\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Denis Guedj (PERSON)\n",
            "1940 – April 24, 2010 (DATE)\n",
            "French (NORP)\n",
            "the History of Science at Paris VIII University (ORG)\n",
            "Setif (PERSON)\n",
            "many years (DATE)\n",
            "Theorem (GPE)\n",
            "Paris (GPE)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "                                   Token entity types\n",
            "0                PERSON = People, including fictional\n",
            "1   NORP = Nationalities or religious or political...\n",
            "2   FAC = Buildings, airports, highways, bridges, etc\n",
            "3        ORG = Companies, agencies, institutions, etc\n",
            "4                     GPE = Countries, cities, states\n",
            "5   LOC = Non-GPE locations, mountain ranges, bodi...\n",
            "6   PRODUCT = Objects, vehicles, foods, etc. (Not ...\n",
            "7   EVENT = Named hurricanes, battles, wars, sport...\n",
            "8           WORK_OF_ART = Titles of books, songs, etc\n",
            "9                LAW = Named documents made into laws\n",
            "10                      LANGUAGE = Any named language\n",
            "11       DATE = Absolute or relative dates or periods\n",
            "12                    TIME = Times smaller than a day\n",
            "13                PERCENT = Percentage, including ”%“\n",
            "14            MONEY = Monetary values, including unit\n",
            "15  QUANTITY = Measurements, as of weight or distance\n",
            "16                   ORDINAL = “first”, “second”, etc\n",
            "17  CARDINAL = Numerals that do not fall under ano...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T7A3p05vfcz0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Noun extraction"
      ]
    },
    {
      "metadata": {
        "id": "hetkfphHfcz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "42b3044b-a417-42cf-eeae-77cfabad73fc"
      },
      "cell_type": "code",
      "source": [
        "chunks = betterNLP.extract_nouns_chunks(model, generic_text)\n",
        "chunks = chunks.get(\"noun_chunks\")\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "set_of_noun_chunks = set(chunks)\n",
        "if len(set_of_noun_chunks) == 0:\n",
        "\tprint(\"Did not find words that belong together.\")\n",
        "else:\n",
        "\tprint(\"A list of words that belong together (in lowercase):\")\n",
        "\n",
        "[print(each_noun_chunk) for each_noun_chunk in set_of_noun_chunks if len(each_noun_chunk.split(\" \")) > betterNLP.minimum_occurrence_frequency]\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "A list of words that belong together (in lowercase):\n",
            "many years\n",
            "french novelist\n",
            "children math\n",
            "universal language\n",
            "parrot's theorem\n",
            "denis guedj\n",
            "paris viii university\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s2kyTI6bfcz7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gather facts"
      ]
    },
    {
      "metadata": {
        "id": "dw8PDy9Ofcz8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_topic = \"Denis Guedj\"\n",
        "extracted_facts = betterNLP.extract_facts(model, generic_text, target_topic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aKxvH1Ynfcz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ebb9e111-3c3a-48af-d10f-9429fb6e6eb3"
      },
      "cell_type": "code",
      "source": [
        "extracted_facts = extracted_facts.get(\"facts\")\n",
        "\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Trying to gather details about \" + target_topic)\n",
        "\n",
        "number_of_facts_found = 0\n",
        "for each_fact_statement in extracted_facts:\n",
        "    number_of_facts_found =+ 1\n",
        "    subject, verb, fact = each_fact_statement\n",
        "    print(f\" - {fact}\")\n",
        "\n",
        "if number_of_facts_found == 0:\n",
        "    print(\"There were no facts on \" + target_topic)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Trying to gather details about Denis Guedj\n",
            " - a French novelist and \n",
            "a professor of the History of Science at Paris VIII University\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4jQLb4Sqfc0E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Obfuscate privacy details"
      ]
    },
    {
      "metadata": {
        "id": "_bmI2UcSfc0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5a0f76e8-fe9e-49d9-f779-a9292c190cd6"
      },
      "cell_type": "code",
      "source": [
        "obfuscated_text = betterNLP.obfuscate_text(model, generic_text)\n",
        "obfuscated_text = obfuscated_text.get(\"obfuscated_text\")\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Obfuscated generic text: \", \"\".join(obfuscated_text))\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Obfuscated generic text:  [OBFUSCATED] (1940 – April 24, 2010) was a French novelist and a professor of the History of Science at Paris VIII University. He was born in [OBFUSCATED] . He spent many years devising courses and games to teach adults and children math. He is the author of Numbers: The Universal Language and of the novel The Parrot's Theorem. He died in Paris. \n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H_JfZhqwfc0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}