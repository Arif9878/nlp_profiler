{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFyUOrS1fczL"
   },
   "source": [
    "# Better NLP\n",
    "\n",
    "This is a wrapper program/library that encapsulates a couple of NLP libraries that are popular among the AI and ML communities.\n",
    "\n",
    "Examples have been used to illustrate the usage as much as possible. Not all the APIs of the underlying libraries have been covered.\n",
    "\n",
    "The idea is to keep the API language as high-level as possible, so its easier to use and stays human-readable.\n",
    "\n",
    "Libraries / frameworks covered:\n",
    "\n",
    "- SpaCy ([site](https://spacy.io/) | [docs](https://spacy.io/usage/))\n",
    "- Textacy ([github](https://github.com/chartbeat-labs/textacy) | [docs](https://chartbeat-labs.github.io/textacy/))\n",
    "\n",
    "See [https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp](https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lre8GErufczN"
   },
   "source": [
    "#### Setup and installation ( optional )\n",
    "\n",
    "In case, this notebook is running in a local environment (Linux/MacOS) or _Google Colab_ environment and in case it does not have the necessary dependencies installed then please execute the steps in the next section.\n",
    "\n",
    "Otherwise, please SKIP to the **Examples** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5927
    },
    "colab_type": "code",
    "id": "QJuCUOMOfczO",
    "outputId": "018e9102-de25-4fbe-b5b3-919c58644f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "dpkg is already the newest version (1.18.25).\n",
      "dpkg set to manually installed.\n",
      "The following NEW packages will be installed:\n",
      "  apt-utils dselect libapt-inst2.0\n",
      "0 upgraded, 3 newly installed, 0 to remove and 4 not upgraded.\n",
      "Need to get 1888 kB of archives.\n",
      "After this operation, 4168 kB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian stretch/main amd64 libapt-inst2.0 amd64 1.4.9 [192 kB]\n",
      "Get:2 http://deb.debian.org/debian stretch/main amd64 apt-utils amd64 1.4.9 [410 kB]\n",
      "Get:3 http://deb.debian.org/debian stretch/main amd64 dselect amd64 1.18.25 [1285 kB]\n",
      "Fetched 1888 kB in 1s (1171 kB/s)\n",
      "Selecting previously unselected package libapt-inst2.0:amd64.\n",
      "(Reading database ... 36312 files and directories currently installed.)\n",
      "Preparing to unpack .../libapt-inst2.0_1.4.9_amd64.deb ...\n",
      "Unpacking libapt-inst2.0:amd64 (1.4.9) ...\n",
      "Selecting previously unselected package apt-utils.\n",
      "Preparing to unpack .../apt-utils_1.4.9_amd64.deb ...\n",
      "Unpacking apt-utils (1.4.9) ...\n",
      "Selecting previously unselected package dselect.\n",
      "Preparing to unpack .../dselect_1.18.25_amd64.deb ...\n",
      "Unpacking dselect (1.18.25) ...\n",
      "Setting up libapt-inst2.0:amd64 (1.4.9) ...\n",
      "Setting up apt-utils (1.4.9) ...\n",
      "Setting up dselect (1.18.25) ...\n",
      "Processing triggers for libc-bin (2.24-11+deb9u4) ...\n",
      "OSTYPE=linux-gnu\n",
      "Detected OS: linux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "--2019-04-14 18:54:03--  https://raw.githubusercontent.com/neomatrix369/awesome-ai-ml-dl/master/examples/better-nlp/build//install-linux.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2019-04-14 18:54:04 ERROR 404: Not Found.\n",
      "\n",
      "chmod: cannot access './install-linux.sh': No such file or directory\n",
      "--2019-04-14 18:54:04--  https://raw.githubusercontent.com/neomatrix369/awesome-ai-ml-dl/master/examples/better-nlp/build//install-dependencies.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2019-04-14 18:54:04 ERROR 404: Not Found.\n",
      "\n",
      "chmod: cannot access './install-dependencies.sh': No such file or directory\n",
      "bash: line 31: ./install-linux.sh: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 10 ms, total: 30 ms\n",
      "Wall time: 5.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "apt-get install apt-utils dselect dpkg\n",
    "\n",
    "echo \"OSTYPE=$OSTYPE\"\n",
    "if [[ \"$OSTYPE\" == \"cygwin\" ]] || [[ \"$OSTYPE\" == \"msys\" ]] ; then\n",
    "    echo \"Windows or Windows-like environment detected, script not tested, and may not work.\"\n",
    "    echo \"Try installing the components mention in the install-[ostype].sh scripts manually.\"\n",
    "    echo \"Or try running under CGYWIN or git-bash.\"\n",
    "    echo \"If successfully installed, please contribute back with the solution via a pull request, to https://github.com/neomatrix369/awesome-ai-ml-dl/\"\n",
    "    echo \"Please give the file a good name, i.e. install-windows.sh or install-windows.bat depending on what kind of script you end up writing\"\n",
    "    exit 0\n",
    "elif [[ \"$OSTYPE\" == \"linux-gnu\" ]] || [[ \"$OSTYPE\" == \"linux\" ]]; then\n",
    "    TARGET_OS=\"linux\"\n",
    "else\n",
    "    TARGET_OS=\"macos\"\n",
    "fi\n",
    "\n",
    "BASE_URL=\"https://raw.githubusercontent.com/neomatrix369/awesome-ai-ml-dl/master/examples/better-nlp/build/\"\n",
    "if [[ ! -f \"install-${TARGET_OS}.sh\" ]]; then\n",
    "    wget ${BASE_URL}/install-${TARGET_OS}.sh\n",
    "    chmod +x ./install-${TARGET_OS}.sh\n",
    "fi\n",
    "\n",
    "\n",
    "if [[ ! -f \"install-dependencies.sh\" ]]; then\n",
    "    wget ${BASE_URL}/install-dependencies.sh\n",
    "    chmod +x ./install-dependencies.sh\n",
    "fi\n",
    "\n",
    "echo \"Detected OS: ${TARGET_OS}\"\n",
    "./install-${TARGET_OS}.sh || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtvtZg2afczS"
   },
   "source": [
    "#### Install Spacy model ( NOT optional )\n",
    "\n",
    "Install the large English language model for spaCy - will be needed for the examples in this notebooks.\n",
    "\n",
    "**Note:** from observation it appears that spaCy model should be installed towards the end of the installation process, it avoid errors when running programs using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "HLvwAn-DfczT",
    "outputId": "77fe7daf-6186-4b97-d248-82807d92260e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "python -m spacy download en_core_web_lg\n",
    "python -m spacy link en_core_web_lg en || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-foC9mxEmLjC"
   },
   "source": [
    "#### Clone the repo with the library code\n",
    "\n",
    "Eventually we won't do this, when the library can be installed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcI9FxFfitpj"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [[ -e awesome-ai-ml-dl/examples/better-nlp/ ]] || [[ -e ../../org/neomatrix369 ]]; then\n",
    "   echo \"Library source exists\"\n",
    "else\n",
    "    git clone \"https://github.com/neomatrix369/awesome-ai-ml-dl\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwXgEdM8oeUv"
   },
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AX1pZlKofczb"
   },
   "source": [
    "### Extract entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pe2IZleafczd"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../library')\n",
    "\n",
    "from org.neomatrix369.better_nlp import BetterNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cu1TA5ZJfczi"
   },
   "outputs": [],
   "source": [
    "# Can be any factual text or any text to experiment with\n",
    "generic_text = \"\"\"Denis Guedj (1940 â€“ April 24, 2010) was a French novelist and \n",
    "a professor of the History of Science at Paris VIII University. He was born \n",
    "in Setif. He spent many years devising courses and games to teach adults \n",
    "and children math. He is the author of Numbers: The Universal Language and \n",
    "of the novel The Parrot's Theorem. He died in Paris. \n",
    "\"\"\"\n",
    "\n",
    "betterNLP = BetterNLP() ### do not re-run this unless you wish to re-initialise the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "iaihh-wofczq",
    "outputId": "7b0dfe83-0ab2-4485-e05b-c2605e3292c8"
   },
   "outputs": [],
   "source": [
    "model_loading_result = betterNLP.load_nlp_model()\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"model_loading_time_in_secs=\",model_loading_result['model_loading_time_in_secs'])\n",
    "print(\"model_loading_method=\",model_loading_result['model_loading_method'])\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "model = model_loading_result[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "empjCbipfczu",
    "outputId": "d58b032e-a7d2-41d0-dc07-8e2267f8c552"
   },
   "outputs": [],
   "source": [
    "parsed_generic_text = betterNLP.extract_entities(model, generic_text)\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"extract_entities_processing_time_in_secs=\", parsed_generic_text['extract_entities_processing_time_in_secs'])\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "parsed_generic_text = parsed_generic_text['parsed_text']\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "[print(f\"{each_entity.text} ({each_entity.label_})\") for each_entity in parsed_generic_text.ents if each_entity.text.strip() == each_entity.text]\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(betterNLP.token_entity_types())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7A3p05vfcz0"
   },
   "source": [
    "### Noun extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "hetkfphHfcz2",
    "outputId": "0c6d1d9b-3bd7-45ad-b5df-c3c8cb2feceb"
   },
   "outputs": [],
   "source": [
    "chunks = betterNLP.extract_nouns_chunks(model, generic_text)\n",
    "chunks = chunks.get(\"noun_chunks\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "set_of_noun_chunks = set(chunks)\n",
    "if len(set_of_noun_chunks) == 0:\n",
    "\tprint(\"Did not find words that belong together.\")\n",
    "else:\n",
    "\tprint(\"A list of words that belong together (in lowercase):\")\n",
    "\n",
    "[print(each_noun_chunk) for each_noun_chunk in set_of_noun_chunks if len(each_noun_chunk.split(\" \")) > betterNLP.minimum_occurrence_frequency]\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2kyTI6bfcz7"
   },
   "source": [
    "### Gather facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw8PDy9Ofcz8"
   },
   "outputs": [],
   "source": [
    "target_topic = \"Denis Guedj\"\n",
    "extracted_facts = betterNLP.extract_facts(model, generic_text, target_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "aKxvH1Ynfcz_",
    "outputId": "3a267644-b8cc-41c6-bdca-f5b89a495db5"
   },
   "outputs": [],
   "source": [
    "extracted_facts = extracted_facts.get(\"facts\")\n",
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Trying to gather details about \" + target_topic)\n",
    "\n",
    "number_of_facts_found = 0\n",
    "for each_fact_statement in extracted_facts:\n",
    "    number_of_facts_found =+ 1\n",
    "    subject, verb, fact = each_fact_statement\n",
    "    print(f\" - {fact}\")\n",
    "\n",
    "if number_of_facts_found == 0:\n",
    "    print(\"There were no facts on \" + target_topic)\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4jQLb4Sqfc0E"
   },
   "source": [
    "### Obfuscate privacy details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "_bmI2UcSfc0F",
    "outputId": "049c4553-d542-43f5-8dc3-c479f7c0720d"
   },
   "outputs": [],
   "source": [
    "obfuscated_text = betterNLP.obfuscate_text(model, generic_text)\n",
    "obfuscated_text = obfuscated_text.get(\"obfuscated_text\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Obfuscated generic text: \", \"\".join(obfuscated_text))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_JfZhqwfc0J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "better-nlp-spacy-texacy-examples.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
