{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better NLP\n",
    "\n",
    "This is a wrapper program/library that encapsulates a couple of NLP libraries that are popular among the AI and ML communities.\n",
    "\n",
    "Examples have been used to illustrate the usage as much as possible. Not all the APIs of the underlying libraries have been covered.\n",
    "\n",
    "The idea is to keep the API language as high-level as possible, so its easier to use and stays human-readable.\n",
    "\n",
    "Libraries / frameworks covered:\n",
    "\n",
    "- SpaCy ([site](https://spacy.io/) | [docs](https://spacy.io/usage/))\n",
    "- Textacy ([github](https://github.com/chartbeat-labs/textacy) | [docs](https://chartbeat-labs.github.io/textacy/))\n",
    "\n",
    "See [https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp](https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup and installation ( optional )\n",
    "\n",
    "In case, this notebook is running in a local environment (Linux/MacOS) which does not have the necessary dependencies installed the next section would need to be executed.\n",
    "\n",
    "Otherwise, please SKIP to the **Extract entities** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "apt-get install apt-utils dselect dpkg\n",
    "\n",
    "echo \"OSTYPE=$OSTYPE\"\n",
    "if [[ \"$OSTYPE\" == \"cygwin\" ]] || [[ \"$OSTYPE\" == \"msys\" ]] ; then\n",
    "    echo \"Windows or Windows-like environment detected, script not tested, and may not work.\"\n",
    "    echo \"Try installing the components mention in the install-[ostype].sh scripts manually.\"\n",
    "    echo \"Or try running under CGYWIN or git-bash.\"\n",
    "    echo \"If successfully installed, please contribute back with the solution via a pull request, to https://github.com/neomatrix369/awesome-ai-ml-dl/\"\n",
    "    echo \"Please give the file a good name, i.e. install-windows.sh or install-windows.bat depending on what kind of script you end up writing\"\n",
    "    exit 0\n",
    "elif [[ \"$OSTYPE\" == \"linux-gnu\" ]] || [[ \"$OSTYPE\" == \"linux\" ]]; then\n",
    "    TARGET_OS=\"linux\"\n",
    "else\n",
    "    TARGET_OS=\"macos\"\n",
    "fi\n",
    "\n",
    "BASE_URL=\"https://raw.githubusercontent.com/neomatrix369/awesome-ai-ml-dl/master/examples/better-nlp\"    \n",
    "if [[ ! -f \"install-${TARGET_OS}.sh\" ]]; then\n",
    "    wget \"${BASE_URL}/install-${TARGET_OS}.sh\"\n",
    "fi\n",
    "\n",
    "if [[ ! -f \"install-dependencies.sh\" ]]; then\n",
    "    wget \"${BASE_URL}/install-dependencies.sh\"\n",
    "fi\n",
    "\n",
    "echo \"Detected OS: ${TARGET_OS}\"\n",
    "./install-${TARGET_OS}.sh || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Spacy model ( NOT optional )\n",
    "\n",
    "Install the large English language model for spaCy - will be needed for the examples in this notebooks.\n",
    "\n",
    "**Note:** from observation it appears that spaCy model should be installed towards the end of the installation process, it avoid errors when running programs using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz#egg=en_core_web_lg==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
      "Installing collected packages: en-core-web-lg\n",
      "  Running setup.py install for en-core-web-lg: started\n",
      "    Running setup.py install for en-core-web-lg: finished with status 'done'\n",
      "Successfully installed en-core-web-lg-2.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.7/site-packages/en_core_web_lg -->\n",
      "/usr/local/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t7m37.473s\n",
      "user\t1m28.250s\n",
      "sys\t0m55.550s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "time python -m spacy download en_core_web_lg\n",
    "python -m spacy link en_core_web_lg en || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from org.neomatrix369.better_nlp import BetterNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be any factual text or any text to experiment with\n",
    "generic_text = \"\"\"Denis Guedj (1940 – April 24, 2010) was a French novelist and \n",
    "a professor of the History of Science at Paris VIII University. He was born \n",
    "in Setif. He spent many years devising courses and games to teach adults \n",
    "and children math. He is the author of Numbers: The Universal Language and \n",
    "of the novel The Parrot's Theorem. He died in Paris. \n",
    "\"\"\"\n",
    "\n",
    "betterNLP = BetterNLP() ### do not re-run this unless you wish to re-initialise the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 'en'...\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "model_loading_time_in_secs= 30.775343894958496\n",
      "model_loading_method= directly, first time\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "model_loading_result = betterNLP.load_nlp_model()\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"model_loading_time_in_secs=\",model_loading_result['model_loading_time_in_secs'])\n",
    "print(\"model_loading_method=\",model_loading_result['model_loading_method'])\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "model = model_loading_result[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "extract_entities_processing_time_in_secs= 0.09914803504943848\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Denis Guedj (PERSON)\n",
      "1940 – April 24, 2010 (DATE)\n",
      "French (NORP)\n",
      "the History of Science (ORG)\n",
      "Paris VIII University (ORG)\n",
      "Setif (NORP)\n",
      "many years (DATE)\n",
      "The Parrot's Theorem (WORK_OF_ART)\n",
      "Paris (GPE)\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "                                   Token entity types\n",
      "0                PERSON = People, including fictional\n",
      "1   NORP = Nationalities or religious or political...\n",
      "2   FAC = Buildings, airports, highways, bridges, etc\n",
      "3        ORG = Companies, agencies, institutions, etc\n",
      "4                     GPE = Countries, cities, states\n",
      "5   LOC = Non-GPE locations, mountain ranges, bodi...\n",
      "6   PRODUCT = Objects, vehicles, foods, etc. (Not ...\n",
      "7   EVENT = Named hurricanes, battles, wars, sport...\n",
      "8           WORK_OF_ART = Titles of books, songs, etc\n",
      "9                LAW = Named documents made into laws\n",
      "10                      LANGUAGE = Any named language\n",
      "11       DATE = Absolute or relative dates or periods\n",
      "12                    TIME = Times smaller than a day\n",
      "13                PERCENT = Percentage, including ”%“\n",
      "14            MONEY = Monetary values, including unit\n",
      "15  QUANTITY = Measurements, as of weight or distance\n",
      "16                   ORDINAL = “first”, “second”, etc\n",
      "17  CARDINAL = Numerals that do not fall under ano...\n"
     ]
    }
   ],
   "source": [
    "parsed_generic_text = betterNLP.extract_entities(model, generic_text)\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"extract_entities_processing_time_in_secs=\", parsed_generic_text['extract_entities_processing_time_in_secs'])\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "parsed_generic_text = parsed_generic_text['parsed_text']\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "[print(f\"{each_entity.text} ({each_entity.label_})\") for each_entity in parsed_generic_text.ents if each_entity.text.strip() == each_entity.text]\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(betterNLP.token_entity_types())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "A list of words that belong together (in lowercase):\n",
      "children math\n",
      "many years\n",
      "paris viii university\n",
      "1940 – april\n",
      "parrot's theorem\n",
      "french novelist\n",
      "universal language\n",
      "denis guedj\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "chunks = betterNLP.extract_nouns_chunks(model, generic_text)\n",
    "chunks = chunks.get(\"noun_chunks\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "set_of_noun_chunks = set(chunks)\n",
    "if len(set_of_noun_chunks) == 0:\n",
    "\tprint(\"Did not find words that belong together.\")\n",
    "else:\n",
    "\tprint(\"A list of words that belong together (in lowercase):\")\n",
    "\n",
    "[print(each_noun_chunk) for each_noun_chunk in set_of_noun_chunks if len(each_noun_chunk.split(\" \")) > betterNLP.minimum_occurrence_frequency]\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_topic = \"Denis Guedj\"\n",
    "extracted_facts = betterNLP.extract_facts(model, generic_text, target_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Trying to gather details about Denis Guedj\n",
      " - a French novelist and \n",
      "a professor of the History of Science at Paris VIII University\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "extracted_facts = extracted_facts.get(\"facts\")\n",
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Trying to gather details about \" + target_topic)\n",
    "\n",
    "number_of_facts_found = 0\n",
    "for each_fact_statement in extracted_facts:\n",
    "    number_of_facts_found =+ 1\n",
    "    subject, verb, fact = each_fact_statement\n",
    "    print(f\" - {fact}\")\n",
    "\n",
    "if number_of_facts_found == 0:\n",
    "    print(\"There were no facts on \" + target_topic)\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obfuscate privacy details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Obfuscated generic text:  [OBFUSCATED] (1940 – April 24, 2010) was a French novelist and a professor of the History of Science at Paris VIII University. He was born in Setif. He spent many years devising courses and games to teach adults and children math. He is the author of Numbers: The Universal Language and of the novel The Parrot's Theorem. He died in Paris. \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "obfuscated_text = betterNLP.obfuscate_text(model, generic_text)\n",
    "obfuscated_text = obfuscated_text.get(\"obfuscated_text\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Obfuscated generic text: \", \"\".join(obfuscated_text))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
